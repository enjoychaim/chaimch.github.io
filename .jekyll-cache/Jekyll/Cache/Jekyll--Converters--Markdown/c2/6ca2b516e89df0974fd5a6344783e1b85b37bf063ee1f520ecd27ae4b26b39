I"0<h2 id="问题">问题</h2>

<ol>
  <li>kubernates 是什么？</li>
  <li>kubernates 解决了什么问题？</li>
  <li>kubernates 该如何使用？</li>
  <li>集群中资源是如何调度的？</li>
</ol>

<h2 id="k8s-是什么-解决了什么问题">k8s 是什么, 解决了什么问题</h2>

<p>kubernates 是 Google 公司开源的一个容器编排与调度管理框架, 当前由 CNCF 托管.</p>

<p>解决了分布式系统情况下, 容器的编排与调度问题.</p>

<h3 id="发展历史">发展历史</h3>

<ol>
  <li>
    <p>2003-2004 年, Google 发布 Borg 系统, 3-4 人开发.</p>

    <p>主要用于管理长时间运行的生产服务和批处理服务. Brog 将上述两种服务所需要的的机器统一成一个池子, 以便提高资源利用率, 同时降低成本.</p>

    <p>之所以能够实现跨机器的资源共享以及进程隔离, 是因为可以拿到 Linux 内核的容器支持.</p>
  </li>
  <li>
    <p>… 年, 越来越多的应用被开发并运行在 Borg上, Google 团队开发了一个工具系统.</p>

    <p>工具系统提供配合和更新 job 的机制, 可以预测资源需求, 动态的推送配置文件, 服务发现, 负载均衡, 自动扩容, 机器的生命周期管理, 额度管理等等.</p>

    <p>由于要适配不同团队的需求, Borg 发展成了 ad-hoc 系统(即席查询, 用户根据自己的需求，灵活的选择查询条件，系统能够根据用户的选择生成相应的统计报表)集合, Borg 使用者可以使用不同的配置语言和进程来配置与沟通.</p>
  </li>
  <li>
    <p>2006-2007 年, Paul Menage和Rohit Seth 提出了 cgroups, 并且被合并到2.6.24版的内核中</p>
  </li>
  <li>
    <p>2013 年左右, 处于提升 Borg 生态系统软件工程的愿景, Google 发布了 Omega 集群管理系统.</p>

    <p>Omega 把很多 Borg 内已经被认证的成功的模式搬过来, 同时从头开始搭建一个更加一致性的构架. 添加了控制面板, 调度器等等, 以此来优化偶尔发生的资源冲突问题.  同年, docker 正式出道.</p>
  </li>
  <li>
    <p>2014 年左右, Google 发布了 kubernates. 同年, Microsoft, Red Hat, IBM, Docker 等加入 kubernates 社区</p>
  </li>
  <li>
    <p>2015 年, 成立了 CNCF 基金会, 托管 kubernates</p>
  </li>
  <li>
    <p>2016 年左右, kubernates 成为主流.</p>

    <p>在 CloudNative 2016 大会上, 来自全世界的贡献值和开发者一起交流kubernates, Fluentd, Promethues等云原生技术(采用开源堆栈 K8S+Docker 进行容器化，基于微服务架构提高灵活性和可维护性，借助敏捷方法、DevOps支持持续迭代和运维自动化，利用云平台设施实现弹性伸缩、动态调度、优化资源利用率)</p>
  </li>
  <li>
    <p>2017 年左右, 各大互联网厂商开始纷纷支持 kubernates. 同年, istio 正式出道. Docker 容器大战正式结束, 成功上位, 作为 kubernates 容器运行时的标配.</p>
  </li>
  <li>
    <p>2018 年左右, 无人不知 kubernates. 国内不论大小厂商开始进行云原生落地.</p>
  </li>
</ol>

<h3 id="borgomegak8s关联">Borg/Omega/K8S关联</h3>

<p>参见: <a href="https://queue.acm.org/detail.cfm?id=2898444">Borg/Omega/K8S关联</a></p>

<h3 id="k8s特点">k8s特点</h3>

<ol>
  <li>可移植性: 支持公有云, 私有云, 混合云, 多重云</li>
  <li>可扩展性: 模块化, 插件化, 可挂载, 可组合</li>
  <li>自动化: 自动部署, 自动重启, 自动复制, 自动伸缩/扩展</li>
</ol>

<h2 id="k8s-该如何使用">k8s 该如何使用</h2>

<h3 id="环境准备篇">环境准备篇</h3>

<h4 id="本地开发环境">本地开发环境</h4>
<p>参见: <a href="https://github.com/chaimch/k8s-for-docker-desktop">本地开发环境</a></p>

<h4 id="云羊毛环境">云羊毛环境</h4>
<p>参见一: <a href="https://console.cloud.google.com/freetrial">GCP 羊毛</a></p>

<p>参见二: <a href="https://katacoda.com/learn">katacoda 羊毛</a></p>

<h3 id="入门">入门</h3>

<h4 id="自动补全提示">自动补全提示</h4>
<ol>
  <li>安装 bash-completion <code class="language-plaintext highlighter-rouge">yum install bash-completion</code></li>
  <li>设置 kubectl 的别称 <code class="language-plaintext highlighter-rouge">alias k=kubectl</code></li>
  <li>bash 环境下, 调整别称 k 的自动补全 <code class="language-plaintext highlighter-rouge">source &lt;(kubectl completion bash | sed s/kubectl/k/g)</code></li>
  <li>zsh 环境下, 调整 k 的自动补全 <code class="language-plaintext highlighter-rouge">source &lt;(kubectl completion zsh)</code></li>
  <li>设置切换名称空间别称 <code class="language-plaintext highlighter-rouge">alias kcd='k config set-context $(k config current-context) --namespace'</code></li>
</ol>

<h4 id="hello-world">hello world</h4>

<p>创建配置</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
</code></pre></div></div>

<p>创建应用</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create -f 我的配置文件
</code></pre></div></div>

<p>查看应用</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get pods -l app=nginx
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-67594d6bf6-9gdvr   1/1       Running   0          10m
nginx-deployment-67594d6bf6-v6j7w   1/1       Running   0          10m
</code></pre></div></div>

<h4 id="kubernates-官方">Kubernates 官方</h4>

<p>参见: <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Kubernates Tutorials</a></p>

<h3 id="为什么需要-pod">为什么需要 Pod</h3>

<p>容器的本质是进程, Kubernates 的本质是操作系统</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pstree -g
systemd(1)-+-accounts-daemon(1984)-+-{gdbus}(1984)
           | `-{gmain}(1984)
           |-acpid(2044)
          ...      
           |-lxcfs(1936)-+-{lxcfs}(1936)
           | `-{lxcfs}(1936)
           |-mdadm(2135)
           |-ntpd(2358)
           |-polkitd(2128)-+-{gdbus}(2128)
           | `-{gmain}(2128)
           |-rsyslogd(1632)-+-{in:imklog}(1632)
           |  |-{in:imuxsock) S 1(1632)
           | `-{rs:main Q:Reg}(1632)
           |-snapd(1942)-+-{snapd}(1942)
           |  |-{snapd}(1942)
           |  |-{snapd}(1942)
           |  |-{snapd}(1942)
           |  |-{snapd}(1942)
</code></pre></div></div>

<p>在真正的操作系统中, 进程往往是以进程组的方式被组织在一起. 比如 rsyslogd 程序, 负责 linux 日志处理. 其中主程序 main, 和内核日志模块 imklog 等同属于 1632 进程组. 这些进程之间相互协作.</p>

<p>如果将 rsyslogd 应用容器化, 由于受限于容器的“单进程模型”(容器没有管理多个进程的能力)，这三个模块往往需要被分别制作成三个不同的容器. 一旦 main 容器所在的节点不足以承担三个容器同时运行时候, 就容易出现成组调度问题.</p>

<p>但是在 Kubernates 中就存在这种问题, Pod 是 Kubernetes 里的原子调度单位, 统一按照 Pod 而非容器的资源需求进行计算的.</p>

<h3 id="架构图">架构图</h3>
<p><img src="https://cdn.jsdelivr.net/gh/chaimch/FigureBed@master/uPic/architecture.png" alt="architecture" /></p>

<h3 id="组件功能">组件功能</h3>

<h4 id="kubectl">kubectl</h4>
<p>官方提供的 CLI, 可以以交互式对 Kubernates API Server 进行操作. kubectl 发送相应的 http 请求, 由 Kubernates API Server 处理后返回并展示出结果.</p>

<h4 id="kube-apiserver">kube-apiserver</h4>

<p>负责将 Kubernates 的资源组/资源版本/资源以 restful 风格的形式对外暴露并提供服务. Kubernates 集群中的所有组件都通过 kube-apiserver 组件操作资源对象.</p>

<h5 id="特点">特点</h5>

<ol>
  <li>所有资源对象都封装成 restful 风格的 api 接口进行管理</li>
  <li>集群状态管理和数据管理, 是唯一与 etcd 集群交互的组件</li>
  <li>拥有丰富的集群安全访问机制, 以及认证, 授权及准入控制器</li>
</ol>

<h4 id="kube-controller-manager">kube-controller-manager</h4>

<p>管理 Kubernates 集群中Node节点, Pod副本, 服务, Endpoint端点, Namespace 命名空间, Service Account 服务账户, ResourceQuota 等. eg: 某个节点宕机时候,  Controller Manager 会及时发现并执行自动化修复流程.</p>

<p>Controller Manager 具备高可用性, 基于 etcd 集群上的分布式锁实现领导者选举机制. 多个实例同时运行,  通过 kube-apiserver 提供的资源锁进行选举竞争.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">简化版本的 Kubernates 架构图</th>
      <th style="text-align: center">简易版本冰箱架构</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://cdn.jsdelivr.net/gh/chaimch/FigureBed@master/uPic/image-20200908125907635.png" alt="image-20200908125907635" /></td>
      <td style="text-align: center"><img src="https://cdn.jsdelivr.net/gh/chaimch/FigureBed@master/uPic/image-20200908130029579.png" alt="image-20200908130029579" /></td>
    </tr>
  </tbody>
</table>

<p>类似冰箱一样, 对 Kubernates 的操作都需要统一的入口管理, 即通过 api-server .</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">冰箱 V1.0</th>
      <th style="text-align: center">冰箱 V2.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://cdn.jsdelivr.net/gh/chaimch/FigureBed@master/uPic/image-20200908131150235.png" alt="image-20200908131150235" /></td>
      <td style="text-align: center"><img src="https://cdn.jsdelivr.net/gh/chaimch/FigureBed@master/uPic/image-20200908131220428.png" alt="image-20200908131220428" /></td>
    </tr>
  </tbody>
</table>

<p>控制器专门用于控制各个系统的状态. 打开门时候, 控制器监控到门的变化, 替用户打开灯. 用户按下温控器时候, 控制器观察到用户设置的温度, 则它替用户去管理制冷系统.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">冰箱 V3.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://cdn.jsdelivr.net/gh/chaimch/FigureBed@master/uPic/image-20200908131321132.png" alt="image-20200908131321132" /></td>
    </tr>
  </tbody>
</table>

<h4 id="kube-scheduler">kube-scheduler</h4>

<p>Kubernates 集群的默认调度器, 主要负责在 Kubernates 集群中为一个 Pod 资源对象找到合适的节点, 并在该节点上运行. 该调度器为每个 Pod 寻找合适节点的过程称之为调度周期, 一个调度周期之内只调度一个 Pod 资源对象. 该组件监控整个集群的 Pod 资源对象和 Node 资源对象, 一旦有新的 Pod 资源对象时, 会通过调度算法为其选择最优的节点.</p>

<h4 id="kubelet">kubelet</h4>

<p>该组件运行在每个 Kubernates 集群中的节点上, 用于接收, 处理, 上报 kube-apiserver 组件下发的任务.</p>

<p>Kubelet 进程启动时会向 Kube-apiserver 注册节点自身信息, 定时上报所在节点的资源使用状态, 用以帮助kube-schedule 调度器为 Pod 资源对象预选节点.</p>

<p>同时负责所在节点上的 Pod 资源对象的管理(Pod 资源对象的创建, 修改, 监控, 删除, 驱逐及Pod 声明周期管理等), 对所在节点的镜像和容器做一些清理工作, 保证节点上的镜像不会占满磁盘空间, 删除容器释放相关资源.</p>

<p>kubelet 开放的接口, CRI 容器运行时接口, CNI 容器网络接口, CSI 容器存储接口.</p>

<h4 id="kube-proxy">kube-proxy</h4>

<p>节点上的网络代理, 监控 kube-apiserver 服务于端点资源变化, 同时可以通过 iptables/ipvs 等配置负载均衡器, 为一组 pod 提供统一的 tcp/udp 的流量转发和负载均衡功能.</p>

:ET